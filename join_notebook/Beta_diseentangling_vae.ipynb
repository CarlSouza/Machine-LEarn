{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from configparser import ConfigParser\n",
    "\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disvae import init_specific_model, Trainer, Evaluator\n",
    "from disvae.utils.modelIO import save_model, load_model, load_metadata\n",
    "from disvae.models.losses import LOSSES, RECON_DIST, get_loss_f\n",
    "from disvae.models.vae import MODELS\n",
    "from utils.datasets import get_dataloaders, get_img_size, DATASETS\n",
    "from utils.helpers import (create_safe_directory, get_device, set_seed, get_n_param,\n",
    "                           get_config_section, update_namespace_, FormatterNoDuplicate)\n",
    "\n",
    "CONFIG_FILE = \"hyperparam.ini\"\n",
    "RES_DIR = \"results\"\n",
    "LOG_LEVELS = list(logging._levelToName.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments(args_to_parse):\n",
    "    \"\"\"Parse the command line arguments.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args_to_parse: list of str\n",
    "        Arguments to parse (splitted on whitespaces).\n",
    "    \"\"\"\n",
    "    default_config = get_config_section([CONFIG_FILE], \"Custom\")\n",
    "\n",
    "    description = \"PyTorch implementation and evaluation of disentangled Variational AutoEncoders and metrics.\"\n",
    "    parser = argparse.ArgumentParser(description=description,\n",
    "                                     formatter_class=FormatterNoDuplicate)\n",
    "\n",
    "    # General options\n",
    "    general = parser.add_argument_group('General options')\n",
    "    general.add_argument('name', type=str,\n",
    "                         help=\"Name of the model for storing and loading purposes.\")\n",
    "    general.add_argument('-L', '--log-level', help=\"Logging levels.\",\n",
    "                         default=default_config['log_level'], choices=LOG_LEVELS)\n",
    "    general.add_argument('--no-progress-bar', action='store_true',\n",
    "                         default=default_config['no_progress_bar'],\n",
    "                         help='Disables progress bar.')\n",
    "    general.add_argument('--no-cuda', action='store_true',\n",
    "                         default=default_config['no_cuda'],\n",
    "                         help='Disables CUDA training, even when have one.')\n",
    "    general.add_argument('-s', '--seed', type=int, default=default_config['seed'],\n",
    "                         help='Random seed. Can be `None` for stochastic behavior.')\n",
    "\n",
    "    # Learning options\n",
    "    training = parser.add_argument_group('Training specific options')\n",
    "    training.add_argument('--checkpoint-every',\n",
    "                          type=int, default=default_config['checkpoint_every'],\n",
    "                          help='Save a checkpoint of the trained model every n epoch.')\n",
    "    training.add_argument('-d', '--dataset', help=\"Path to training data.\",\n",
    "                          default=default_config['dataset'], choices=DATASETS)\n",
    "    # training.add_argument('-x', '--experiment',\n",
    "    #                       default=default_config['experiment'], choices=EXPERIMENTS,\n",
    "    #                       help='Predefined experiments to run. If not `custom` this will overwrite some other arguments.')\n",
    "    training.add_argument('-e', '--epochs', type=int,\n",
    "                          default=default_config['epochs'],\n",
    "                          help='Maximum number of epochs to run for.')\n",
    "    training.add_argument('-b', '--batch-size', type=int,\n",
    "                          default=default_config['batch_size'],\n",
    "                          help='Batch size for training.')\n",
    "    training.add_argument('--lr', type=float, default=default_config['lr'],\n",
    "                          help='Learning rate.')\n",
    "\n",
    "    # Model Options\n",
    "    model = parser.add_argument_group('Model specfic options')\n",
    "    model.add_argument('-m', '--model-type',\n",
    "                       default=default_config['model'], choices=MODELS,\n",
    "                       help='Type of encoder and decoder to use.')\n",
    "    model.add_argument('-z', '--latent-dim', type=int,\n",
    "                       default=default_config['latent_dim'],\n",
    "                       help='Dimension of the latent variable.')\n",
    "    model.add_argument('-l', '--loss',\n",
    "                       default=default_config['loss'], choices=LOSSES,\n",
    "                       help=\"Type of VAE loss function to use.\")\n",
    "    model.add_argument('-r', '--rec-dist', default=default_config['rec_dist'],\n",
    "                       choices=RECON_DIST,\n",
    "                       help=\"Form of the likelihood ot use for each pixel.\")\n",
    "    model.add_argument('-a', '--reg-anneal', type=float,\n",
    "                       default=default_config['reg_anneal'],\n",
    "                       help=\"Number of annealing steps where gradually adding the regularisation. What is annealed is specific to each loss.\")\n",
    "\n",
    "    # Loss Specific Options\n",
    "    betaH = parser.add_argument_group('BetaH specific parameters')\n",
    "    betaH.add_argument('--betaH-B', type=float,\n",
    "                       default=default_config['betaH_B'],\n",
    "                       help=\"Weight of the KL (beta in the paper).\")\n",
    "\n",
    "    betaB = parser.add_argument_group('BetaB specific parameters')\n",
    "    betaB.add_argument('--betaB-initC', type=float,\n",
    "                       default=default_config['betaB_initC'],\n",
    "                       help=\"Starting annealed capacity.\")\n",
    "    betaB.add_argument('--betaB-finC', type=float,\n",
    "                       default=default_config['betaB_finC'],\n",
    "                       help=\"Final annealed capacity.\")\n",
    "    betaB.add_argument('--betaB-G', type=float,\n",
    "                       default=default_config['betaB_G'],\n",
    "                       help=\"Weight of the KL divergence term (gamma in the paper).\")\n",
    "\n",
    "    # Learning options\n",
    "    evaluation = parser.add_argument_group('Evaluation specific options')\n",
    "    evaluation.add_argument('--is-eval-only', action='store_true',\n",
    "                            default=default_config['is_eval_only'],\n",
    "                            help='Whether to only evaluate using precomputed model `name`.')\n",
    "    evaluation.add_argument('--is-metrics', action='store_true',\n",
    "                            default=default_config['is_metrics'],\n",
    "                            help=\"Whether to compute the disentangled metrcics. Currently only possible with `dsprites` as it is the only dataset with known true factors of variations.\")\n",
    "    evaluation.add_argument('--no-test', action='store_true',\n",
    "                            default=default_config['no_test'],\n",
    "                            help=\"Whether not to compute the test losses.`\")\n",
    "    evaluation.add_argument('--eval-batchsize', type=int,\n",
    "                            default=default_config['eval_batchsize'],\n",
    "                            help='Batch size for evaluation.')\n",
    "\n",
    "    args = parser.parse_args(args_to_parse)\n",
    "\n",
    "\n",
    "    return args\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    \"\"\"Main train and evaluation function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args: argparse.Namespace\n",
    "        Arguments\n",
    "    \"\"\"\n",
    "\n",
    "    set_seed(args.seed)\n",
    "    device = get_device()\n",
    "    exp_dir = os.path.join(RES_DIR, args.name)\n",
    "\n",
    "    if not args.is_eval_only:\n",
    "\n",
    "        create_safe_directory(exp_dir)\n",
    "\n",
    "        # PREPARES DATA\n",
    "        train_loader = get_dataloaders(args.dataset,\n",
    "                                       batch_size=args.batch_size,\n",
    "                                       )\n",
    "\n",
    "        # PREPARES MODEL\n",
    "        args.img_size = get_img_size(args.dataset)  # stores for metadata\n",
    "        model = init_specific_model(args.model_type, args.img_size, args.latent_dim)\n",
    "        print('Num parameters in model: {}'.format(get_n_param(model)))\n",
    "\n",
    "        # TRAINS\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "        model = model.to(device)  # make sure trainer and viz on same device\n",
    "        # gif_visualizer = GifTraversalsTraining(model, args.dataset, exp_dir)\n",
    "        loss_f = get_loss_f(args.loss,\n",
    "                            n_data=len(train_loader.dataset),\n",
    "                            device=device,\n",
    "                            **vars(args))\n",
    "        trainer = Trainer(model, optimizer, loss_f,\n",
    "                          device=device,\n",
    "                          save_dir=exp_dir,\n",
    "                          is_progress_bar=not args.no_progress_bar #,\n",
    "                          #gif_visualizer=gif_visualizer\n",
    "                          )\n",
    "        trainer(train_loader,\n",
    "                epochs=args.epochs,\n",
    "                checkpoint_every=args.checkpoint_every,)\n",
    "\n",
    "        # SAVE MODEL AND EXPERIMENT INFORMATION\n",
    "        save_model(trainer.model, exp_dir, metadata=vars(args))\n",
    "\n",
    "    if args.is_metrics or not args.no_test:\n",
    "        model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "        metadata = load_metadata(exp_dir)\n",
    "        # TO-DO: currently uses train datatset\n",
    "        test_loader = get_dataloaders(metadata[\"dataset\"],\n",
    "                                      batch_size=args.eval_batchsize,\n",
    "                                      shuffle=False)\n",
    "        \n",
    "        loss_f = get_loss_f(args.loss,\n",
    "                            n_data=len(test_loader.dataset),\n",
    "                            device=device,\n",
    "                            **vars(args))\n",
    "        \n",
    "        evaluator = Evaluator(model, loss_f,\n",
    "                              device=device,\n",
    "                              save_dir=exp_dir,\n",
    "                              is_progress_bar=not args.no_progress_bar)\n",
    "\n",
    "        evaluator(test_loader, is_metrics=args.is_metrics, is_losses=not args.no_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num parameters in model: 502005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    }
   ],
   "source": [
    "args_to_parse = 'juliana-tests-v1 -d chairs -l betaH --betaH-B 3 --lr 0.001 -b 64 -e 4'.split()\n",
    "\n",
    "args = parse_arguments(args_to_parse)\n",
    "main(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from utils.helpers import FormatterNoDuplicate, check_bounds, set_seed\n",
    "from utils.visualize import Visualizer\n",
    "from utils.viz_helpers import get_samples\n",
    "from disvae.utils.modelIO import load_model, load_metadata\n",
    "\n",
    "\n",
    "PLOT_TYPES = ['generate-samples', 'data-samples', 'reconstruct', \"traversals\",\n",
    "              'reconstruct-traverse', \"gif-traversals\", \"all\"]\n",
    "\n",
    "\n",
    "def parse_arguments_viz(args_to_parse):\n",
    "    \"\"\"Parse the command line arguments.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args_to_parse: list of str\n",
    "        Arguments to parse (splitted on whitespaces).\n",
    "    \"\"\"\n",
    "    description = \"CLI for plotting using pretrained models of `disvae`\"\n",
    "    parser = argparse.ArgumentParser(description=description,\n",
    "                                     formatter_class=FormatterNoDuplicate)\n",
    "\n",
    "    parser.add_argument('name', type=str,\n",
    "                        help=\"Name of the model for storing and loading purposes.\")\n",
    "    parser.add_argument(\"plots\", type=str, nargs='+', choices=PLOT_TYPES,\n",
    "                        help=\"List of all plots to generate. `generate-samples`: random decoded samples. `data-samples` samples from the dataset. `reconstruct` first rnows//2 will be the original and rest will be the corresponding reconstructions. `traversals` traverses the most important rnows dimensions with ncols different samples from the prior or posterior. `reconstruct-traverse` first row for original, second are reconstructions, rest are traversals. `gif-traversals` grid of gifs where rows are latent dimensions, columns are examples, each gif shows posterior traversals. `all` runs every plot.\")\n",
    "    parser.add_argument('-s', '--seed', type=int, default=None,\n",
    "                        help='Random seed. Can be `None` for stochastic behavior.')\n",
    "    parser.add_argument('-r', '--n-rows', type=int, default=6,\n",
    "                        help='The number of rows to visualize (if applicable).')\n",
    "    parser.add_argument('-c', '--n-cols', type=int, default=7,\n",
    "                        help='The number of columns to visualize (if applicable).')\n",
    "    parser.add_argument('-t', '--max-traversal', default=2,\n",
    "                        type=lambda v: check_bounds(v, lb=0, is_inclusive=False,\n",
    "                                                    type=float, name=\"max-traversal\"),\n",
    "                        help='The maximum displacement induced by a latent traversal. Symmetrical traversals are assumed. If `m>=0.5` then uses absolute value traversal, if `m<0.5` uses a percentage of the distribution (quantile). E.g. for the prior the distribution is a standard normal so `m=0.45` corresponds to an absolute value of `1.645` because `2m=90%%` of a standard normal is between `-1.645` and `1.645`. Note in the case of the posterior, the distribution is not standard normal anymore.')\n",
    "    parser.add_argument('-i', '--idcs', type=int, nargs='+', default=[],\n",
    "                        help='List of indices to of images to put at the begining of the samples.')\n",
    "    parser.add_argument('-u', '--upsample-factor', default=1,\n",
    "                        type=lambda v: check_bounds(v, lb=1, is_inclusive=True,\n",
    "                                                    type=int, name=\"upsample-factor\"),\n",
    "                        help='The scale factor with which to upsample the image (if applicable).')\n",
    "    parser.add_argument('--is-show-loss', action='store_true',\n",
    "                        help='Displays the loss on the figures (if applicable).')\n",
    "    parser.add_argument('--is-posterior', action='store_true',\n",
    "                        help='Traverses the posterior instead of the prior.')\n",
    "    args = parser.parse_args(args_to_parse)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def main_viz(args):\n",
    "    \"\"\"Main function for plotting fro pretrained models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args: argparse.Namespace\n",
    "        Arguments\n",
    "    \"\"\"\n",
    "    set_seed(args.seed)\n",
    "    experiment_name = args.name\n",
    "    model_dir = os.path.join(RES_DIR, experiment_name)\n",
    "    meta_data = load_metadata(model_dir)\n",
    "    model = load_model(model_dir)\n",
    "    model.eval()  # don't sample from latent: use mean\n",
    "    dataset = meta_data['dataset']\n",
    "    viz = Visualizer(model=model,\n",
    "                     model_dir=model_dir,\n",
    "                     dataset=dataset,\n",
    "                     max_traversal=args.max_traversal,\n",
    "                     loss_of_interest='kl_loss_',\n",
    "                     upsample_factor=args.upsample_factor)\n",
    "    size = (args.n_rows, args.n_cols)\n",
    "    # same samples for all plots: sample max then take first `x`data  for all plots\n",
    "    num_samples = args.n_cols * args.n_rows\n",
    "    samples = get_samples(dataset, num_samples, idcs=args.idcs)\n",
    "\n",
    "    if \"all\" in args.plots:\n",
    "        args.plots = [p for p in PLOT_TYPES if p != \"all\"]\n",
    "\n",
    "    for plot_type in args.plots:\n",
    "        if plot_type == 'generate-samples':\n",
    "            viz.generate_samples(size=size)\n",
    "        elif plot_type == 'data-samples':\n",
    "            viz.data_samples(samples, size=size)\n",
    "        elif plot_type == \"reconstruct\":\n",
    "            viz.reconstruct(samples, size=size)\n",
    "        elif plot_type == 'traversals':\n",
    "            viz.traversals(data=samples[0:1, ...] if args.is_posterior else None,\n",
    "                           n_per_latent=args.n_cols,\n",
    "                           n_latents=args.n_rows,\n",
    "                           is_reorder_latents=True)\n",
    "        elif plot_type == \"reconstruct-traverse\":\n",
    "            viz.reconstruct_traverse(samples,\n",
    "                                     is_posterior=args.is_posterior,\n",
    "                                     n_latents=args.n_rows,\n",
    "                                     n_per_latent=args.n_cols,\n",
    "                                     is_show_text=args.is_show_loss)\n",
    "        elif plot_type == \"gif-traversals\":\n",
    "            viz.gif_traversals(samples[:args.n_cols, ...], n_latents=args.n_rows)\n",
    "        else:\n",
    "            raise ValueError(\"Unkown plot_type={}\".format(plot_type))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['juliana-tests-v0', 'traversals', '--is-show-loss']\n",
      "Selected idcs: [57767, 15315, 981, 11880, 76313, 4577, 11001, 12900, 46482, 31039, 2284, 4038, 2076, 45362, 84976, 81694, 63471, 80716, 60758, 19471, 11965, 23998, 14996, 1916, 65940, 63799, 32745, 8462, 70921, 61066, 8987, 78835, 11656, 67507, 75891, 6024, 35335, 72932, 8267, 84493, 39639, 63050]\n"
     ]
    }
   ],
   "source": [
    "args_viz = 'juliana-tests-v0 traversals --is-show-loss'.split()\n",
    "print(args_viz)\n",
    "args = parse_arguments_viz(args_viz)\n",
    "main_viz(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['juliana-tests-v0', 'generate-samples', '--is-show-loss']\n",
      "Selected idcs: [46561, 34924, 32656, 85915, 26218, 59426, 69489, 2529, 66597, 9252, 757, 43713, 18844, 61974, 86160, 49459, 21903, 7100, 9992, 77008, 65087, 21496, 9872, 73050, 28192, 18906, 3555, 45381, 14534, 69426, 18511, 40028, 59525, 5189, 54558, 36278, 5269, 23244, 35608, 20259, 39357, 20257]\n"
     ]
    }
   ],
   "source": [
    "args_viz = 'c'.split()\n",
    "print(args_viz)\n",
    "args = parse_arguments_viz(args_viz)\n",
    "main_viz(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['juliana-tests-v1', 'all', '--is-show-loss']\n",
      "Selected idcs: [57767, 15315, 981, 11880, 76313, 4577, 11001, 12900, 46482, 31039, 2284, 4038, 2076, 45362, 84976, 81694, 63471, 80716, 60758, 19471, 11965, 23998, 14996, 1916, 65940, 63799, 32745, 8462, 70921, 61066, 8987, 78835, 11656, 67507, 75891, 6024, 35335, 72932, 8267, 84493, 39639, 63050]\n"
     ]
    }
   ],
   "source": [
    "args_viz = 'juliana-tests-v1 all --is-show-loss'.split()\n",
    "print(args_viz)\n",
    "args = parse_arguments_viz(args_viz)\n",
    "main_viz(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
